{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - Deep Learning and Neural Networks with Python and Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3272, 0.2127, 0.7687, 0.9407, 0.0799],\n",
      "        [0.7465, 0.6607, 0.9115, 0.0305, 0.8235],\n",
      "        [0.7314, 0.2455, 0.7837, 0.6715, 0.3235]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand([3, 5])\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([3, 3])\n",
    "b = torch.Tensor([2, 1])\n",
    "\n",
    "torch.set_printoptions(profile=\"ful\", edgeitems=3)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros([2,5])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally the pytorch lib is a library that allows us to do math on arrays (where tensors are just multi dimensional arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Data\n",
    "\n",
    "We will use the MNist Dataset as an example\n",
    "\n",
    "In these examples we have datasets prepared for us, which removes the often most time consuming task of the process of training a model which is the preparing/labelling/organising of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define our datasets.\n",
    "We will split them into 2\n",
    "- training \n",
    "- testing (out-of sample data)\n",
    "\n",
    "This is so we don't overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train = datasets.MNIST(\"\", train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "We batch for 2 reasons:\n",
    " 1. Often times we will have large datasets and \n",
    "    not all the data can fit in memory at once\n",
    "\n",
    " 2. We hope the data will generalize\n",
    "    Remove chance of data not generalising.\n",
    "    If you pass your whole data set at once, your machine\n",
    "    is more likely to pickup a bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  common batch sizes are 8 - 64\n",
    "trainSet = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "\n",
    "testSet = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 9, 3, 4, 5, 7, 7, 1, 1, 2])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainSet:\n",
    "  print(data)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# data contains two tensors\n",
    "# 1st index: Tensor of Tensors of image data\n",
    "# 2nd index: Tensor of labels\n",
    "x,y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec7a84dfd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following two prints show us the percentage distribution of the training set\n",
      "{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n",
      "0: 9.8\n",
      "1: 11.35\n",
      "2: 10.32\n",
      "3: 10.100000000000001\n",
      "4: 9.82\n",
      "5: 8.92\n",
      "6: 9.58\n",
      "7: 10.280000000000001\n",
      "8: 9.74\n",
      "9: 10.09\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainSet:\n",
    "  xs, ys = data\n",
    "  for y in ys:\n",
    "    counter_dict[int(y)] += 1\n",
    "    total+=1\n",
    "\n",
    "print(\"The following two prints show us the percentage distribution of the training set\")\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "  print(f\"{i}: {counter_dict[i]/total * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    # this will call the init method of nn Module\n",
    "    super().__init__()\n",
    "    # here we will setup our layers\n",
    "    # fc stands for fully connected\n",
    "    inputFeatureCount = 28*28; # because our images are 28px squared\n",
    "    self.fc1 =nn.Linear(inputFeatureCount, 64)\n",
    "    self.fc2 =nn.Linear(64, 64)\n",
    "    self.fc3 =nn.Linear(64, 64)\n",
    "    self.fc4 =nn.Linear(64, 10)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "302b45b043b81e89ca211c616643d2e149c3f30fc1401ebdf96b411cbc165aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
